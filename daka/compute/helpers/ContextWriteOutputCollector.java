package daka.compute.helpers;

import java.io.IOException;

import org.apache.hadoop.io.Writable;
import org.apache.hadoop.mapred.OutputCollector;
import org.apache.hadoop.mapreduce.Reducer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * An output collector for Reducer for PFPGrowth which updates the
 * status as well as writes the patterns generated by the algorithm
 * 
 * @param <IK>
 * @param <IV>
 * @param <K>
 * @param <V>
 */
public class ContextWriteOutputCollector<IK extends Writable, IV extends Writable, K extends Writable, V extends Writable>
		implements OutputCollector<K, V>
{

	private static final Logger log = LoggerFactory
			.getLogger(ContextWriteOutputCollector.class);

	private final Reducer<IK, IV, K, V>.Context context;

	public ContextWriteOutputCollector(Reducer<IK, IV, K, V>.Context context)
	{
		this.context = context;
	}

	@Override
	public final void collect(K key, V value) throws IOException
	{
		try
		{
			context.setStatus("Writing Top K patterns for: " + key);
			context.write(key, value);
		} catch (InterruptedException e)
		{
			log.error("{}", e.toString());
		}
	}

}
